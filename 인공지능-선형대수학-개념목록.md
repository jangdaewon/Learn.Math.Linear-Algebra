인공지능(AI), 특히 딥러닝은 수많은 데이터를 숫자의 집합으로 처리합니다. 이때 데이터를 효율적으로 계산하고 변환하는 핵심 도구가 바로 **선형대수학(Linear Algebra)**입니다.
AI 개발을 위해 반드시 알아야 할 핵심 개념들을 단계별로 정리해 드릴게요.

---

### 1. 데이터의 기본 단위 (Data Representation)

데이터를 어떤 형식으로 담느냐에 대한 기초 개념입니다.

* **스칼라(Scalar):** 하나의 숫자. (예: )
* **벡터(Vector):** 숫자의 나열(1차원 배열). 공간에서의 방향과 크기를 나타냅니다.
* **행렬(Matrix):** 숫자의 2차원 배열. 데이터셋 자체나 가중치(Weight)를 표현합니다.
* **텐서(Tensor):** 3차원 이상의 고차원 배열. 딥러닝 프레임워크(PyTorch, TensorFlow)의 기본 단위입니다.

### 2. 행렬 연산 (Matrix Operations)

신경망 내부에서 데이터가 흐를 때 일어나는 계산들입니다.

* **행렬 곱(Matrix Multiplication / Dot Product):** 가중치와 입력 데이터를 계산할 때 가장 많이 쓰이는 연산입니다.
* **전치 행렬(Transpose Matrix):** 행과 열을 바꾼 행렬입니다. 연산 시 차원을 맞추기 위해 사용합니다.
* **역행렬(Inverse Matrix):** $A\mathbf{x} = \mathbf{b}$에서 $\mathbf{x}$를 구할 때 필요하며, 모델의 해를 찾는 과정에서 중요합니다.
* **단위 행렬(Identity Matrix):** 곱해도 자기 자신이 나오는 행렬로, 숫자의 '1'과 같은 역할을 합니다.

### 3. 선형 시스템과 공간 (Linear Systems & Spaces)

데이터가 존재하는 공간의 성질을 이해하는 데 필요합니다.

* **선형 결합(Linear Combination):** 벡터들에 상수를 곱해 더하는 연산입니다.
* **기저(Basis)와 차원(Dimension):** 공간을 구성하는 최소한의 벡터 집합과 그 개수입니다.
* **선형 독립(Linear Independence):** 벡터들이 서로 중복된 정보를 가지고 있지 않은 상태를 의미합니다.
* **랭크(Rank):** 행렬에서 독립적인 행이나 열의 개수(정보의 유효 차원)입니다.

---

### 4. 고유값 분해와 차원 축소 (Decomposition)

복잡한 데이터를 핵심 정보만 남기고 압축하거나 특징을 추출할 때 필수적입니다.

* **고유값(Eigenvalue) & 고유벡터(Eigenvector):** 선형 변환을 해도 방향이 변하지 않는 특수한 벡터와 그 크기 변화량입니다.
* **고유값 분해(Eigendecomposition):** 행렬을 고유값과 고유벡터의 곱으로 분해하는 것입니다.
* **특이값 분해(SVD, Singular Value Decomposition):** 모든 행렬에 적용 가능한 분해 기법으로, 추천 시스템이나 데이터 압축에 널리 쓰입니다.
* **주성분 분석(PCA):** 데이터의 분산을 최대한 보존하면서 차원을 줄이는 핵심 알고리즘입니다.

### 5. 거리와 크기 측정 (Norms)

모델의 오차를 계산하거나 과적합(Overfitting)을 방지할 때 사용합니다.

* **L1 노름(L1 Norm):** 벡터 성분의 절대값 합 (Manhattan distance).
* **L2 노름(L2 Norm):** 벡터의 직선 거리 (Euclidean distance). 가중치 규제(Regularization)에 주로 쓰입니다.

---
